# -*- coding: utf-8 -*-
"""Dataset_extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SyWmDai1MRINkWXxZ995QQ8uL3sCzpgg
"""

pip install snscrape

import pandas as pd

import snscrape
import snscrape.modules
import snscrape.modules.twitter

tweets=[]

for i, tweet in enumerate(snscrape.modules.twitter.TwitterSearchScraper("#coronavirus+#pandemic+#covid19 lang:en since:2020-10-01 until:2020-10-20").get_items()):
  if tweet not in tweets:
    tweets.append(tweet)
  if i>=1500:
    break
 
"""
P.S - This code block needs to run multiple times with respect to the hashtags, 'since' and 'until' parameters in order to obtain a specific number of tweets per month(which has been done using
enumerate function). 
The way this works - enter the required 'since' and 'until' dates with the required query or hashtag according to required iterable value and run the cell/code block so that these tweets are 
appended to the list called - tweets.

Repeat this until process until requirement is satisfied.

P.P.S - Initially we extracted 28053 tweets but we found that it wasnt fitting our requirement later on (for ABSA), so we had to reduce the tweets in the dataset to suit our requirements. 
We recommend to check resources and requirements and change the parameters as required.
We have added the dataset used for this project - final dataset.csv, please find it for reference if required.
"""

len(tweets)

df=pd.DataFrame(tweets)

from google.colab import drive
drive.mount('/drive')

df.head()

df1 = df[['url','date','content','id','username']]

df1.head()

df1.to_csv("/drive/My Drive/Mini_Project/final_dataset.csv", mode="a")
